# Source codes for paper: Text Mining from Migration Narratives

## **Note**: Due to the ethical guidelines, we could not provide the entire corpus of narratives for running from scratch. Instead, we have preprocessed all the necessary files to reproduce the results reported in this paper. Please follow all the instructions below for reproducibility.


## A brief explanation for each folder
-**text_mining_from_migration_narratives/**: This folder contains all source codes and files necessary for the reproducible results.

1. `annotatated_mention_entity`: folder contains all the annotation of English and French narratives for location recognition and disambiguation generated by experts.
2. `BELA`: contain all the necessary source codes for running location disambiguation. 
3. `dataset`: folder contains all the necessary data of English and French narratives for running MultiWidthExpan algorithm.
4. `scripts`: folder contains all the scripts to generate the entire experiments used in our paper which we will describe in detail in the following paragraph.
5. `TermExtraction`: folder contains all the scripts and necessary files for running automatic term extraction using method TF-IDF

## Detailed explanation for each folder

1. `annotated_mention_entity`: contains all the annotated and disambiguated locations manually annotated by experts
   - `annotated_english_recits.json` and `annotated_english_recits.json`: contain all the annotated and disambiguated entities using Wikidata for English and French narratives respectively.
   - `annotated_english_recits_with_geonamesId.json` and `annotated_english_recits_with_geonamesId.json`: All the annotated and disambiguated entities containing Wikidata IDs and GeoNames IDs for English and French narratives, respectively. Later, we will provide an example of how to obtain GeoNames IDs using Wikidata IDs.
   - `pre-output_flair_english_recits.json`, `pre-output_flair_french_recits.json`, `pre-output_spacy_english_recits.json`, `pre-output_spacy_french_recits.json`, `pre-output_stanza_english_recits.json` and `pre-output_stanza_french_recits.json`: Since we could not provide the entire narrative texts for reproducing the results, we instead provide the pre-output of each NER model on our narratives to get the reproducible results for both English and French using `Flair`, `SpaCy`, and `Stanza`, respectively.
2. `BELA`: This source code is originally from https://github.com/facebookresearch/BELA/tree/main. We modified some parts to adapt with our use case. We will provide the instructions later on how to run location disambiguation using BELA.
3. `dataset`: contains EN, FR. Each folder contains the beginner, embeddings, intermediate, and KB folders.
    - `beginner`: there is one Excel file that contains all the extracted terms using TF-IDF score sorted in descending order.
    - `embeddings`: store the embeddings pre-trained skip-gram model for english: https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip, and pre-trained CBOW model for french: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz. (You do not need to download these models as we already preprocessed everything and store in the folder **intermediate**)
    - `intermediate`: store all the necessary .txt files for running the reproducible results for MultiWidthExpan and presented as follows:
        + **entity2id.txt:** each line has two columns (separated by a “\t” character) and represents one entity. The first column is entity surface name (with an underscore concatenating all words) and the second column is the entityID (which will be the unique identifier to retrieve each entity’s features).
        + **eidSkipgramCounts.txt:** each line has three columns (separated by a “\t” character). The first column is an entity id. The second column is a Skipgram feature associated with this entity. In the skipgram, the occurrence position of the entity is replaced with the placeholder “__”. Finally, the third column is the co-occurrence count between this entity id and the skipgram. For example, the line “36 \t which __ we took \t 2” means “entity with id 36 appears twice in the context which __ we took”.
        + **eidSkipgram2TFIDFStrength.txt:** (**equation (1)** in the paper), each line has four columns (separated by a “\t” character). The first and second columns are exactly the same as the **eidSkipgramCounts.txt**. The third and fourth columns are the association strength between entity and skipgram features. Larger values in third/fourth columns indicate stronger association between entity and skipgram features.
        + **eidTypeCounts.txt:** each line has three columns (separated by a “\t” character). The first column is an entity id. The second column is a type feature (in current version, the type is retrieved from Probase for English and French from Camembert Masked Language Model: https://huggingface.co/almanach/camembert-base) associated with this entity. The third column is the probability that this entity has the corresponding type. For example, the line “1 \t environment \t 0.011990407673860911” means “the probability that entity with id 1 is of type environment is 0.011990407673860911”
        + **eidType2TFIDFStrength.txt:** (**equation (2)** in the paper), each line has four columns (separated by a “\t” character). The first and second columns are exactly the same as the **eidTypeCounts.txt**. The third and fourth columns are normalized probability. Larger values in third/fourth columns indicate stronger association between entity and type features.
        + **eid2embed.txt:** each line is the embedding of one entity. This file is not human-readable.
        + **linked_results.txt:** each line has two columns (separated by a “\t” character). The first column is the entity surface name (no underscore) used as Probase linking input. The second column is the linking results. If an entity can not be linked, then the second column will simply be an empty list []. Otherwise, the second column will be a list of tuples and each tuple is (type name, linking probability). The linking probability indicates how likely an entity has the type. By analyzing this file, we can easily get how many entities are linkable to Probase. Note that for french narratives, we use CamemBERT with cloze-style to obtain the types of entities for creating a KB. 
4. `Geonames`: contains a file name **clean_all_geonames_rdf_african_countries.txt** extracted from Geonames' database: http://download.geonames.org/all-geonames-rdf.zip for only some African countries.
5. `scripts`: contains all the necessary scripts that we describe one by one following the alphabet order
   1. `SetExpan`: contains all the scripts to run Width Expansion algorithm. To see the initialized annotated terms and all the annotated terms, see the script **seedLoader.py**
   2. `automatic_term_extraction.py`: script to run the automatic term extraction from migration narrative texts for both English and French using method TF-IDF.
   3. `extract_geonames_by_country.py`: script to filter some countries related to migration in our study in order to visualize those locations. We extract from all the geonames database available here: http://download.geonames.org/all-geonames-rdf.zip. We already ran and generated the output in: `Geonames/clean_all_geonames_rdf_african_countries.txt`
   4. `flair_location_detection.py`: script to run location recognition using Flair framework.
   5. `generate_bela_input_format_for_evaluation.py`: script to generate the input format for evaluating location disambiguation using BELA. We already ran this script using the files `/annotated_mention_entity/annotated_english_recits.json` and `/annotated_mention_entity/annotated_french_recits.json` and generated the output in: `/BELA/data/narrative-text/`
   6. `get_geonamesId_and_Info_using_wikidataId.py`: script to get the geonames IDs and some specific information such as longitudes and latitudes about the geographical location given the Wikidata IDs. 
   7. `spacy_location_detection.py`: script to run location recognition using Spacy framework.
   8. `stanza_location_detection.py`: script to run location recognition using Stanza framework.
6. `TermExtraction`: contains all the necessary scripts and folders to run automatic term extraction using the combination of linguistic method and statistic method (TF-IDF)
   
# Prerequisites to reproduce the results reported in our paper
Some necessary python packages needed to execute the codes:

- In directory **text_mining_from_migration_narratives/**, create a virtual environment. For example, we want to create a virtual env called venv_narrative with python3.8: 

```
user@pc-user:~text_mining_from_migration_narratives$ python3.8 -m venv venv_narrative
```


- Activate the vitual environment using:

```
user@pc-user:~text_mining_from_migration_narratives$ source venv_narrative/bin/activate
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$
```

- Next, run: **pip install --upgrade pip**


```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ pip install --upgrade pip
```

- After that: **pip install --upgrade wheel**

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ pip install --upgrade wheel
```

- Finally, please run: **pip install -r requirements.txt**

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ pip install -r requirements.txt
```

## To run the reproducible results of MultiWidthExpan
- For English corpus:

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ python run_en_MultiWidthExpan.py
```

+ Output results:


```
=== MultiSetExpan at iteration 10 ===
Annotated Sets: 
{'Accommodation': ['homes', 'home', 'house', 'houses', 'hostel', 'room', 'rooms', 'hotel', 'apartment', 'tent', 'tents', 'bed', 'shelter', 'floor', 'garage', 'building'], 'Means of transport': ['foot', 'walk', 'autobus', 'car', 'cars', 'taxi', 'taxis', 'cab', 'bus', 'buses', 'minibus', 'van', 'vans', 'minivan', 'minivans', 'trucks', 'truck', 'tractor', 'trains', 'train', 'tram', 'boat', 'ship', 'ferry', 'plane', 'airplane', 'road', 'flight'], 'Environment': ['jungle', 'jungles', 'forest', 'forests', 'trees', 'mountain', 'mountains', 'desert', 'hill', 'valley', 'rocks', 'beach', 'coast', 'island', 'islands', 'river', 'sea', 'seaside'], 'Family Members': ['family', 'father', 'mother', 'grandfather', 'grandmother', 'grandchildren', 'parents', 'dad', 'mum', 'mom', 'brother', 'brothers', 'sister', 'sisters', 'relatives', 'relative', 'cousin', 'cousins', 'uncle', 'wife', 'husband', 'kids', 'child', 'son', 'sons', 'daughter', 'daughters', 'sister_in_law', 'children', 'friends', 'friend']}

Set of Seed entities: 
{'Accommodation': ['home', 'shelter'], 'Means of transport': ['boat', 'train', 'plane'], 'Environment': ['jungle', 'island'], 'Family Members': ['mom', 'relative', 'daughter']}

Threshold: 
{'en': {'Accommodation': 0.74, 'Means of transport': 0.72, 'Environment': 0.7, 'Family Members': 0.75}}

Expanded results: 
{'Accommodation': ['room', 'tent', 'hotel', 'tents', 'homes', 'apartment', 'bathroom', 'houses', 'bed', 'cabin', 'floor', 'restaurant', 'garage', 'building', 'accommodation', 'door', 'dormitories', 'house', 'kitchen', 'shop', 'hostel', 'doors', 'shops', 'parking', 'rooms', 'toilets'], 'Means of transport': ['luggage', 'minivan', 'petrol', 'minibus', 'bus', 'trains', 'passengers', 'cars', 'passenger', 'taxi', 'taxis', 'cab', 'tram', 'ride', 'trucks', 'flight', 'ship', 'truck', 'tractor', 'vans', 'car', 'minivans', 'buses', 'helicopters', 'airplane', 'ferry'], 'Environment': ['southwest', 'valley', 'coast', 'river', 'mountains', 'seaside', 'sea', 'south', 'mountain', 'land', 'jungles', 'beach', 'islands', 'area', 'forests', 'hill', 'region', 'forest', 'desert'], 'Family Members': ['children', 'dad', 'brother', 'housewife', 'cousin', 'parents', 'sisters', 'relatives', 'nephew', 'grandmother', 'friends', 'grandchildren', 'friend', 'father', 'daughters', 'elder', 'uncle', 'cousins', 'sister', 'grandfather', 'brothers', 'child', 'wife', 'son', 'mother', 'husband', 'boyfriend', 'marriage', 'sons', 'family']}

After  10  iterations
{'Accommodation': {'precision': 0.5384615384615384, 'recall': 1.0, 'f1_score': 0.7000000000000001}, 'Means of transport': {'precision': 0.7692307692307693, 'recall': 0.8, 'f1_score': 0.7843137254901961}, 'Environment': {'precision': 0.7368421052631579, 'recall': 0.875, 'f1_score': 0.7999999999999999}, 'Family Members': {'precision': 0.8333333333333334, 'recall': 0.8928571428571429, 'f1_score': 0.8620689655172413}}
```

- For French corpus:

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ python run_fr_MultiWidthExpan.py
```

+ Output results:


```
=== Taxonomy Tree at iteration 10 ===
Annotated Sets: 
{'Hébergement': ['maison', 'appartement', 'chambre', 'chambres', 'maisonnette', 'hôtel', 'domicile', 'foyer', 'tentes', 'tente', 'bâtiment', 'bâtisse', 'immeuble', 'auberge', 'cabane', 'église', 'maisons', 'ferme', 'asile', 'salle'], 'Moyens de transport': ['bateau', 'camion', 'camions', 'pickup', 'marche', 'pied', 'transport_commun', 'autobus', 'train', 'bus', 'avion', 'convoi', 'véhicule', 'véhicules', 'taxi', 'taxis', 'minibus', '4x4', 'autocar', 'voiture', 'voitures', 'vol', 'métro', 'remorque', 'fourgonnette', 'route', 'autoroute', 'rail', 'routes', 'tram'], 'Environnement': ['désert', 'forêt', 'forêts', 'montagne', 'montagnes', 'brousse', 'mer', 'collines', 'rivière', 'île', 'jungle', 'lac', 'broussaille', 'océan'], 'Membres de famille': ['oncle', 'oncles', 'père', 'frère', 'grand-frère', 'cousin', 'cousins', 'grand-père', 'parent', 'parents', 'mère', 'famille', 'tante', 'sœur', 'sœurs', 'maman', 'frères', 'papa', 'tonton', 'fils', 'mari', 'frangin', 'cadet', 'amie', 'ami', 'copain', 'compatriote', 'compatriotes', 'fille', 'copine', 'camarade', 'compagnon', 'compagnons', 'tuteur', 'amis']}

Set of Seed entities: 
{'Hébergement': ['appartement', 'tente'], 'Moyens de transport': ['avion', 'taxi', 'métro'], 'Environnement': ['forêt', 'mer'], 'Membres de famille': ['parents', 'frères', 'cousin']}

Threshold: 
{'fr': {'Hébergement': 0.72, 'Moyens de transport': 0.76, 'Environnement': 0.8, 'Membres de famille': 0.75}}

Expanded results: 
{'Hébergement': ['auberge', 'hôtel', 'rue', 'immeuble', 'ville', 'bâtisse', 'église', 'école', 'maisonnette', 'asile', 'domicile', 'foyer', 'bâtiment', 'maison', 'jardin', 'chambre', 'salle', 'ferme', 'chambres', 'maisons', 'village', 'cabane', 'étage'], 'Moyens de transport': ['camion', 'véhicule', 'autobus', 'fourgonnette', 'aéroport', 'voitures', 'hélicoptères', 'hélicoptère', 'vélo', 'remorque', 'tram', 'rail', 'véhicules', 'autoroute', 'fourgons', 'routes', '4x4', 'bus', 'chauffeur', 'convoi', 'taxis', 'voiture', 'bateau', 'train', 'camions', 'minibus', 'route', 'autocar'], 'Environnement': ['rivière', 'montagnes', 'forêts', 'terre', 'désert', 'brousse', 'broussaille', 'montagne', 'jungle', 'côte', 'océan', 'île', 'lac'], 'Membres de famille': ['homme', 'copine', 'sœurs', 'copain', 'femme', 'ami', 'parent', 'pote', 'oncle', 'compatriote', 'papa', 'cadet', 'jeune', 'mari', 'oncles', 'mère', 'famille', 'frangin', 'maman', 'compagnon', 'sœur', 'compatriotes', 'amie', 'frère', 'fille', 'tonton', 'grand-père', 'camarade', 'amis', 'cousins', 'fils', 'grand-frère', 'père', 'tante']}

After  10  iterations
{'Hébergement': {'precision': 0.7391304347826086, 'recall': 0.9444444444444444, 'f1_score': 0.8292682926829269}, 'Moyens de transport': {'precision': 0.7857142857142857, 'recall': 0.8148148148148148, 'f1_score': 0.7999999999999999}, 'Environnement': {'precision': 0.8461538461538461, 'recall': 0.9166666666666666, 'f1_score': 0.8799999999999999}, 'Membres de famille': {'precision': 0.8823529411764706, 'recall': 0.9375, 'f1_score': 0.9090909090909091}}
```

**Note:** We set 10 iterations for MultiWidthExpan for both English and French narratives. However, we can increase it to 15, 20, and so on, as there are no additional high-quality terms available after 10 iterations.


## To run the reproducible results of NER models for both English and French Narratives

- For Flair Framework:

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ python run_flair_location_detection.py
```

+ Output results:


```
English narratives
Average precision:  0.9761729119078745
Average recall:  0.9756644700983196
Average f1-score:  0.9755201481551792
French narratives
Average precision:  0.8615853957109434
Average recall:  0.9029236551769488
Average f1-score:  0.8785930912175921
```

- For Spacy model: we use **en_core_web_trf** for English narratives and **fr_core_news_md** for French narratives

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ python run_spacy_location_detection.py
```

+ Output results:


```
English narratives
Average precision:  0.9865483344508335
Average recall:  0.9619169777940538
Average f1-score:  0.9736490625958484
French narratives
Average precision:  0.8651114974800308
Average recall:  0.9053210488080933
Average f1-score:  0.8822764339775134
```

- For Stanza Framework:

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives$ python run_stanza_location_detection.py
```

+ Output results for English and French narratives:


```
English narratives
Average precision:  0.9842547257401801
Average recall:  0.9304627516859846
Average f1-score:  0.9561322294475528
French narratives
Average precision:  0.8429788724219637
Average recall:  0.9335901418454691
Average f1-score:  0.8813747688729554
```

## To run the reproducible results for the evaluation of location disambiguation using BELA, make sure to have a GPU-equipped machine

In directory `text_mining_from_migration_narratives/BELA`


- First, deactivate the old environment using:

```
(venv_narrative) user@pc-user:~text_mining_from_migration_narratives/BELA$ deactivate
user@pc-user:~text_mining_from_migration_narratives/BELA$
```

- Create a specific environment for BELA using: **python3.8 -m venv venv_bela**, and activate it using:

```
user@pc-user:~text_mining_from_migration_narratives/BELA$ source venv_bela/bin/activate
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$
```

- Run: **pip install --upgrade pip**

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ pip install --upgrade pip
```

- Then, run: **pip install --upgrade wheel**

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ pip install --upgrade wheel
```

- Install the requirements_bela.txt using:

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ pip install -r requirements_bela.txt
```

- Download the pre-trained models using:

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ ./download_models.sh
```

- Download the pre-trained model xlm-roberta-large from this link: https://huggingface.co/FacebookAI/xlm-roberta-large/tree/main.

- First, from directory `/BELA`, go to directory `/xlm-roberta-large`

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ cd xlm-roberta-large
```

- Then, download the model using the commandline as below:

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA/xlm-roberta-large$ wget --content-disposition https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/config.json?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/flax_model.msgpack?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/model.safetensors?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/pytorch_model.bin?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/sentencepiece.bpe.model?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/tf_model.h5?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/tokenizer.json?download=true https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/tokenizer_config.json?download=true
```

- Finally, we can run the evaluation of BELA using SLURM with the following commandline:

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ srun -p processor_name python3 evaluate_location_disambiguation.py
```

For example, we run on processor name `quad_rtx_8000`

```
(venv_bela) user@pc-user:~text_mining_from_migration_narratives/BELA$ srun -p quad_rtx_8000 python3 evaluate_location_disambiguation.py
```

- If we installed properly, the output results should be something like this:

```
ED accuracy on Migration Narratives for English
Loading model from checkpoint ./models/model_wiki.ckpt
Load encoders state from ./models/model_wiki.ckpt
Processing ./data/narrative-text/english_narrative_text_gold.jsonl
29it [00:00, 49.33it/s]
100%|██████████| 29/29 [00:55<00:00,  1.93s/it]
100%|██████████| 12/12 [01:34<00:00,  7.85s/it]
Accuracy 0.9897992760776572, support 3039, skipped 0
ED accuracy on Migration Narratives for French
Loading model from checkpoint ./models/model_wiki.ckpt
Load encoders state from ./models/model_wiki.ckpt
Processing ./data/narrative-text/french_narrative_text_gold.jsonl
3039it [00:00, 1136760.00it/s]
108it [00:00, 366.78it/s]
100%|██████████| 108/108 [01:12<00:00,  1.48it/s]
100%|██████████| 10/10 [01:22<00:00,  8.22s/it]
Accuracy 0.9780650215432825, support 2553, skipped 0
2553it [00:00, 1359063.09it/s]
```

- Note that we ran BELA on the entire corpus for both English and French to produce the above results. However, due to ethical reasons, we only kept a few narratives in both **english_narrative_text_gold.jsonl** and **french_narrative_text_gold.jsonl** for testing purposes.

- The demonstration of how to get the geonames IDs and some specific information such as longitudes and latitudes about the geographical location given the Wikidata IDs can be found here in the notebook: `text_mining_from_migration_narratives/get_GeonamesId_and_Info_using_WikidataId.ipynb`


## Licenses

- **Code**: All files in `scripts/` are licensed under GPLv3. See [LICENSE](LICENSE) for the full text.
- **Data**: The data files in `dataset/EN/recits_EN`, `dataset/FR/recits_FR`, and `BELA/data/narrative-text` are confidential and proprietary.
See [LICENSE-DATA](dataset/LICENSE-DATA) for full terms. Unauthorized redistribution
or public disclosure is prohibited.
